{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Gap (prelaunch) 0.9 - July 2018\n",
    "## NLP and CV Data Engineering Framework\n",
    "\n",
    "<b>[Github] (https://github.com/andrewferlitsch/gap)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Preparation for NLP with Gap (Session 2)\n",
    "\n",
    "Let's dig deeper into the basics. We will be using the <b style='color: saddlebrown'>SYNTAX</b> component in my Gap module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: saddlebrown'>Words</span> Object\n",
    "\n",
    "Let's directly use the <b style='color: saddlebrown'>Words</b> object to control how the text is NLP preprocessed.I will cover the following:\n",
    "\n",
    "    - Syntax Preprocessing\n",
    "    - Text Reduction (Stopwords)\n",
    "    - Parts of Speech Tagging\n",
    "    - De-Identification\n",
    "    - Measurement Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\'\\Desktop\\epipog-nlp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "!cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\'\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\'\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# import the Words class\n",
    "from document import Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntax Preprocessing\n",
    "\n",
    "The <b style='color: saddlebrown'>SYNTAX</b> module supports various keyword parameters to configure how the text is NLP preprocessed. We will cover just a few in this code-along. Let's start with processing text for gender recognition. When the text is preprocessed, an ordered sequential list of Word objects are generated; each consisting a set of key/value pairs.\n",
    "\n",
    "In bare mode, all the text and punctuation is preserved, and no tagging, parts of speech (POS), stemming, lemmatization, name entity recognition (NER) or stopword removal is perform.\n",
    "\n",
    "#### Bare\n",
    "\n",
    "Let's look at the preprocessing of a simple sentence in bare mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': 'The', 'tag': 0}, {'word': 'quick', 'tag': 0}, {'word': 'brown', 'tag': 0}, {'word': 'fox', 'tag': 0}, {'word': 'jumped', 'tag': 0}, {'word': 'over', 'tag': 0}, {'word': 'the', 'tag': 0}, {'word': 'lazy', 'tag': 0}, {'word': 'dog', 'tag': 0}, {'word': '.', 'tag': 23}]\n"
     ]
    }
   ],
   "source": [
    "# Process this well-known typing phrase which contains all 26 letters of the alphabet\n",
    "w = Words('The quick brown fox jumped over the lazy dog.', bare=True)\n",
    "print(w.words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the words property displays a list, where each entry is an object consisting of a word and tag key value pair. I know you don't know what the integer values of the tags mean (see Vocabulary.py). In bare mode, all words are tagged as UNTAGGED (0) and punctuation as PUNCT (23).\n",
    "\n",
    "Note how in bare mode, all words are kept, their capitalization, order and punctuation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords and Stemming\n",
    "\n",
    "Let's do some text reduction. In NLP, a lot of things add very little to the understanding of the text, such as common words like 'the', 'and', 'a', and punctuation. Removing these common words is called stopword removal. There are several lists for doing this, the most common being the Porter list.\n",
    "\n",
    "Additionallly, we can make it easier to match words if we lowercase all the words and remove word endings, such as plural and 'ing'; which is called stemming. Let's give it a try with the same sentence.\n",
    "\n",
    "Note how words like 'the', and 'over' have been removed, the punctuation has been removed, words have been lowercased and 'jumped' has been stemmed to its root word 'jump'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': 'quick', 'tag': 0}, {'word': 'brown', 'tag': 0}, {'word': 'fox', 'tag': 0}, {'word': 'jump', 'tag': 0}, {'word': 'lazi', 'tag': 0}, {'word': 'dog', 'tag': 0}]\n"
     ]
    }
   ],
   "source": [
    "# Stem words using the NLTK Porter stemmer\n",
    "w = Words('The quick brown fox jumped over the lazy dog.', stem='porter')\n",
    "print(w.words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemmers sometimes reduce words into something that isn't the root. Like 'riding' could end up being 'rid', after cutting off 'ing'. Note above how the NLTK Porter stemmer changed 'lazy' into 'lazi'.\n",
    "\n",
    "Different stemmers have different errors. This can be corrected using a lemmatization. Let's repeat the above but use the Gap stemmer which has a lemmatizer correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': 'quick', 'tag': 0}, {'word': 'brown', 'tag': 0}, {'word': 'fox', 'tag': 0}, {'word': 'jump', 'tag': 0}, {'word': 'lazy', 'tag': 0}, {'word': 'dog', 'tag': 0}]\n"
     ]
    }
   ],
   "source": [
    "# Stem words using the Gap stemmer\n",
    "w = Words('The quick brown fox jumped over the lazy dog.', stem='gap')\n",
    "print(w.words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender Recognition\n",
    "\n",
    "The Words object will also recognize gender specific words. We will preprocess four different ways of saying 'father'. In each case, the tag will be set to MALE (15) and each word will be replaced (reduced) with its common equivalent 'father'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 15, 'word': 'father'},\n",
       " {'tag': 15, 'word': 'father'},\n",
       " {'tag': 15, 'word': 'father'},\n",
       " {'tag': 15, 'word': 'father'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's recognize various forms of father\n",
    "w = Words(\"dad daddy father papa\", gender=True)\n",
    "w.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try a variety of words indicating the gender FEMALE (16). Note now 'mom' and 'mother' got reduced to the common equivalent 'mother', and the slang 'auntie' and 'sis' got reduced to 'aunt' and sister', respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 16, 'word': 'girl'},\n",
       " {'tag': 16, 'word': 'lady'},\n",
       " {'tag': 16, 'word': 'mother'},\n",
       " {'tag': 16, 'word': 'mother'},\n",
       " {'tag': 16, 'word': 'aunt'},\n",
       " {'tag': 16, 'word': 'sister'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Words(\"girl lady mother mom auntie sis\", gender=True)\n",
    "w.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NER (Name Entity Recognition)\n",
    "\n",
    "The <b style='color: saddlebrown'>SYNTAX</b> module will recognize a wide variety of proper names, places and identification, such as a person's name (11), a social security number (9) a title (33), geographic location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a string with a name, social security number, and title.\n",
    "w = Words(\"Patient: Jim Jones, SSN: 123-12-1234. Dr. Nancy Lou\", stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's print the word list. Note that jim and jones are tagged 11 (Proper Name), 123121234 is tagged 9 (SSN), and \n",
    "# Dr is tagged 33 (Title)\n",
    "w.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try an address. Nice, in our example we recognized (tagged) a street number (27), street direction (28), street name (29), street type (30), a secondary address unit (36), a city (31), a state (32) and postal code (34).\n",
    "\n",
    "Both US and Canadian street and postal addresses are recognized. Note how the state name \"Oregon\" got replaced with its ISO internal standard code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 27, 'word': '124'},\n",
       " {'tag': 28, 'word': 'northeast'},\n",
       " {'tag': 29, 'word': 'main'},\n",
       " {'tag': 30, 'word': 'avenue'},\n",
       " {'tag': 36, 'word': 'apartment 6'},\n",
       " {'tag': 31, 'word': 'portland'},\n",
       " {'tag': 32, 'word': 'ISO3166-2:US-OR'},\n",
       " {'tag': 34, 'word': '97221'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Words(\"124 NE Main Ave, Apt #6, Portland, OR 97221\", address=True)\n",
    "w.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### De-Identification\n",
    "\n",
    "The <b style='color: saddlebrown'>SYNTAX</b> module supports de-identification of the text. One can remove names, dates of birth, gender, social security number, telephone numbers and addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 0, 'word': 'patient'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's remove any names and SSN from our text\n",
    "w = Words(\"Patient: Jim Jones, SSN: 123-12-1234\", name=False, ssn=False)\n",
    "w.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measurements\n",
    "\n",
    "The <b style='color: saddlebrown'>SYNTAX</b> module supports extracting measurement units, such as height, weight, speed, volume and quantity (38). You can also configure to convert measurements (25) to Standard or Metric system. A wide variety of acronyms and formats are recognized. Note that numbers are tagged as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 38, 'word': 'height'},\n",
       " {'tag': 1, 'word': '5'},\n",
       " {'tag': 25, 'word': 'foot'},\n",
       " {'tag': 1, 'word': '7'},\n",
       " {'tag': 25, 'word': 'inch'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do height using ' for foot and \" for inches\n",
    "w = Words(\"Height: 5'7\\\"\", stopwords=True)\n",
    "w.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 38, 'word': 'height'},\n",
       " {'tag': 1, 'word': '5'},\n",
       " {'tag': 25, 'word': 'foot'},\n",
       " {'tag': 1, 'word': '7'},\n",
       " {'tag': 25, 'word': 'inch'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do height using the acronym ft and in.\n",
    "w = Words(\"Height: 5 ft 7 in\", stopwords=True)\n",
    "w.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 38, 'word': 'height'},\n",
       " {'tag': 1, 'word': '5'},\n",
       " {'tag': 25, 'word': 'foot'},\n",
       " {'tag': 1, 'word': '7'},\n",
       " {'tag': 25, 'word': 'inch'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do height using the acronym ft and in, with no space between the value and unit\n",
    "w = Words(\"Height: 5ft 7in\", stopwords=True)\n",
    "w.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 38, 'word': 'weight'},\n",
       " {'tag': 21, 'word': 'is'},\n",
       " {'tag': 1, 'word': '54.431039999999996'},\n",
       " {'tag': 25, 'word': 'kilogram'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do an example in Standard and convert to Metric system.\n",
    "w = Words(\"Weight is 120lbs\", stopwords=True, metric=True)\n",
    "w.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THAT'S ALL FOR SESSION 2\n",
    "\n",
    "Look forward to seeing everyone again on session 3 where we will do some data preparation for computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
