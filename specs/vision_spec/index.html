<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Vision - Gap-ML</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Vision";
    var mkdocs_page_input_path = "specs\\vision_spec.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-124527631-1', 'https://andrewferlitsch.github.io/Gap/');
      ga('send', 'pageview');
  </script>
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Gap-ML</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../about/">About</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../org-os/">Organization</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../quick-start-guide/">Quick Start Guide</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Tutorials</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../tutorials/computer_vision/">Computer Vision</a>
                </li>
                <li class="">
                    
    <a class="" href="../../tutorials/natural_language_processing/">Natural Language Processing</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Specifications</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../splitter_spec/">Splitter</a>
                </li>
                <li class="">
                    
    <a class="" href="../syntax_spec/">Syntax</a>
                </li>
                <li class="">
                    
    <a class="" href="../segmentation_spec/">Segmentation</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="./">Vision</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#gap-framework-computer-vision-for-image-data">Gap Framework - Computer Vision for Image Data</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#vision-module">VISION MODULE</a></li>
        
            <li><a class="toctree-l4" href="#1-images">1 Images</a></li>
        
            <li><a class="toctree-l4" href="#2-image">2 Image</a></li>
        
            <li><a class="toctree-l4" href="#appendix-i-updates">APPENDIX I: Updates</a></li>
        
        </ul>
    

    </ul>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Gap-ML</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Specifications &raquo;</li>
        
      
    
    <li>Vision</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="https://github.com/andrewferlitsch/Gap/edit/master/docs/specs/vision_spec.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="gap-framework-computer-vision-for-image-data"><span style='color:saddlebrown'>Gap</span> Framework - Computer Vision for Image Data</h1>
<h2 id="vision-module">VISION MODULE</h2>
<p>High Precision Image Processing<br />
Technical Specification, Gap v0.9.3</p>
<h2 id="1-images">1 Images</h2>
<h3 id="11-images-overview">1.1 Images Overview</h3>
<p>The Images CV preprocessor contains the following primary classes, and their relationships:</p>
<ul>
<li><strong>Images</strong> - This is the base class for the representation of a Computer Vision (CV) preprocessed list of images. The constructor optionally takes as parameters a list of images (paths), and corresponding labels, and flags for CV preprocessing the images into machine learning ready data.</li>
</ul>
<pre><code class="python">images = Images([&lt;list of images&gt;], [&lt;list_of_labels&gt;], flags …)
</code></pre>

<pre><code>Alternately, the list of images can be a list of directories which contain images.
Alternately, the list of images can be a list of URLs of remotely stored images.
Alternately, the list of labels maybe a single value; in which case, the label applies to all the images.
</code></pre>
<ul>
<li>
<p><strong>Image</strong> – This is the base class for the representation of a single Computer Vision (CV). The constructor optionally takes as parameters an image (path), corresponding label, and flags for CV preprocessing the image.</p>
<p>Alternately, the image can be an URL of a remotely stored image.</p>
</li>
</ul>
<p><img alt="images_relationships" src="../../img/specs/images_relationships.png" /></p>
<p>Fig. 1a High Level view of <code>Images</code> Class Object Relationships</p>
<h3 id="12-images-initializer-constructor">1.2 Images Initializer (Constructor)</h3>
<p><strong>Synopsis</strong></p>
<pre><code class="python">Images(images=None, labels= None, dir=’./’, name=None, ehandler=None,  config=None)
</code></pre>

<p><strong>Parameters</strong></p>
<p><strong>images:</strong> If not None, a list of either:<br />
1.  local image files<br />
2.  remote image files (i.e., http[s]://….)<br />
3.  directories of local image files.</p>
<p><strong>labels:</strong> If not None, either:<br />
1.  A single integer value (i.e., label) which corresponds to all the images.<br />
2.  A list of the same size as images parameter list of integer values; where the index of each value is the label for the corresponding index in the images parameter.</p>
<p><strong>dir:</strong> The directory where to store the machine learning ready data.</p>
<p><strong>name:</strong> If not None, a name (string) for the collection.</p>
<p><strong>ehandler:</strong> If not None, the processing of the images into machine learning ready data will be asynchronous, and the value of the parameter is the function (or method) that is the event handler when processing is complete.</p>
<p>The event handler takes the form:</p>
<pre><code class="python">def myHandler(images): 
        # Where images is the Images object that was preprocessed.
</code></pre>

<p><strong>config:</strong> If not None, a list of one or more configuration settings as strings:</p>
<pre><code>    grayscale               | gray  
    flatten                 | flat  
    resize=(height,width)   | resize=height,width  
    thumb=(height,width)    | thumb=height,width  
float=float16       | float32 | float64
    nostore
raw
</code></pre>
<p><strong>Usage</strong></p>
<p>When specified with no parameters, an empty <code>Images</code> object is created. The <code>Images</code> object may then be used to subsequent load (retrieve) previously stored preprocessed machine learning ready data (see <code>load()</code>).</p>
<p>Otherwise, both <code>images</code> and <code>labels</code> parameters must be specified. The <code>labels</code> parameter corresponds to the labels of the images. Each image specified by the <code>images</code> parameter will be preprocessed according to the optional parameters and configuration settings (i.e., <code>config</code> parameter).</p>
<p>By default, the images will be preprocessed as follows:</p>
<ol>
<li>An <code>Image</code> object is created for each image.</li>
<li>The <code>config</code> parameter passed to the <code>Image</code> initializer (constructor) will have the ‘nostore’ setting, which instructs each <code>Image</code> object to not separately store the generated preprocessed machine learning ready data.</li>
<li>Upon completion, the preprocessed machine learning data for each image is stored as a single HDF5 file in the current working directory, unless the <code>config</code> parameter 'nostore' was specified. The root name of the file will be the root name of the first image, preprended with 'collection'. For example, if the first image was <code>cat.jpg</code>, then the root name of the HDF5 will be:</li>
</ol>
<pre><code>collection.cat.h5
</code></pre>

<p>If either or both the <code>dir</code> and <code>config</code> options are not <code>None</code>, they are passed down to each <code>Image</code> object.</p>
<p>If the <code>name</code> parameter is specified, the value will be the root name of the HDF5 stored file.</p>
<p>If the <code>ehandler</code> parameter is not <code>None</code>, then the above will occur asynchronously, and when completed, the corresponding event handler will be called with the <code>Images</code> object passed as a parameter. The <code>ehandler</code> parameter may also be specified as a tuple, where the first item in the tuple is the event handler and the remaining items are arguments to pass to the event handler.</p>
<p>If the path to an image file is remote (i.e., starts with http), an HTTP request will be made to fetch the contents of the file from the remote location.</p>
<p><strong>Exceptions</strong></p>
<p>A <code>TypeError</code> is raised if the type of the parameter is not the expected type.<br />
A <code>AttributeError</code> is raised if an invalid configuration setting is specified.<br />
A <code>IndexError</code> is raised if the size of the labels list does not match the size of the images list.</p>
<h3 id="13-images-properties">1.3 Images Properties</h3>
<h4 id="131-dir">1.3.1 dir</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
path = images.dir

# Setter
images.dir = path           
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter, the property returns the path where the HDF5 file is stored.</p>
<p>When used as a setter, it is only applicable when used in conjunction with the <code>load()</code> or <code>store()</code> methods, indicating where the path where the HDF5 file is found. Otherwise, it is ignored.</p>
<p><strong>Exceptions</strong></p>
<p>A <code>TypeError</code> is raised if the type of the parameter is not the expected type.<br />
A <code>FileNotFoundError</code> is raised if the directory does not exist.</p>
<h4 id="132-name">1.3.2 name</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
collection = images.name
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter the property returns the root name of the HDF5 stored file (also referred to as the name of the collection).</p>
<h4 id="133-images">1.3.3 images</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
images = images.images
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter the property returns the list of Image objects generated for the collection.</p>
<h4 id="134-labels">1.3.4 labels</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
labels = images.labels
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter the property returns the label or list of labels for the collection.</p>
<h4 id="135-time">1.3.5 time</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
secs = images.time
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter the property returns the amount of time (in seconds) it took to preprocess the collection into machine learning ready data.
 </p>
<h4 id="136-split">1.3.6 split</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
x_train, x_test, y_train, y_test = images.split

# Setter
images.split = percent [,seed]      
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a setter, a training and test dataset is generated. The <code>percent</code> parameter specifies the percent that is test data. The data is first randomized before the split. By default, the seed for the split is <code>0</code>. A seed may be optional specified as a second value.  </p>
<p>When repeated, the property will re-split the data and re-randomize it.  </p>
<p>When used as a getter, the split training, test, and corresponding labels are returned as lists converted to numpy arrays, and the labels are one-hot encoded. This is typically used in conjunction with <code>next()</code> operator or <code>minibatch</code> property.  </p>
<p>When the percent is <code>0</code>, the data is not split. All the data will be returned in <code>x_train</code> and <code>y_train</code>, but will still be randomized; <code>x_test</code> and <code>y_test</code> will be <code>None</code>.</p>
<p><strong>Exceptions</strong></p>
<p>A <code>TypeError</code> is raised if the type of the parameter is not the expected type.<br />
A <code>ValueError</code> is raised if a parameter is out of range.<br />
A <code>AttributeError</code> is raised if the number of parameters passed to the setter property is incorrect.</p>
<h4 id="137-minibatch">1.3.7 minibatch</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
generator = images.minibatch

# Setter
images.minibatch = batch_size       
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a setter, the mini-batch size is set.</p>
<p>When used as a getter, a generator is returned. The generator will iterate sequentially through the mini-batches of the training set.  </p>
<p>If the <code>augment</code> property is set to True, for each image in the training set, an additional image is generated by rotating the image a random value between -90 and 90 degrees. Thus, if the mini-batch size is 100 images, the <code>minibatch</code> getter will build a generator for 200 images. See <code>augment</code> for more variations of image augmentation.</p>
<p><strong>Exceptions</strong></p>
<p>A <code>TypeError</code> is raised if the type of the parameter is not the expected type.<br />
A <code>ValueError</code> is raised if the batch_size is out of range.</p>
<h4 id="138-augment">1.3.8 augment</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
augment = images.augment

# Setter
images.augment = True | False

images.augment = (min, max[, n])
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a setter and set to <code>True</code>, image augmentation for rotation is enabled during batch generation (see <code>minibatch</code> and <code>next()</code>). In this mode, for each image, an additional image will be generated that is randomly rotated between -90 and 90 degrees.</p>
<p>When used as a setter and set to a tuple, the min and max boundaries for degree rotation are specified, and optionally the number of augmented images to generate per original image.</p>
<p>When used as a getter, the property returns whether image augmentation is enabled.</p>
<p>The parameter to the <code>augment</code> property may also be a tuple. The tuple specifies the rotation range and optionally the number of agumented images to generate per image; otherwise defaults to one. In the example below:</p>
<p><strong>Exceptions</strong></p>
<p>A <code>TypeError</code> is raised if the type of the parameter is not the expected type.</p>
<h4 id="139-flatten">1.3.9 flatten</h4>
<pre><code class="python">images.flatten = True | False
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a setter and set to <code>True</code>, the machine learning ready data is flatten to a 1D vector.</p>
<p>When used as a setter and set to <code>False</code>, the machine learning ready data is unflatten back to a 2D (gray) or 3D (color) matrix.</p>
<p><strong>Exceptions</strong></p>
<p>A <code>TypeError</code> is raised if the type of the parameter is not the expected type.</p>
<h4 id="1310-resize">1.3.10 resize</h4>
<pre><code class="python">images.resize = (height, width)
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a setter, the machine learning ready data is resized to the specified height and width.</p>
<p><strong>Exceptions</strong></p>
<p>A <code>TypeError</code> is raised if the type of the parameter is not the expected type.</p>
<h3 id="14-images-overridden-operators">1.4 Images Overridden Operators</h3>
<h4 id="141-len">1.4.1 len()</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python">n_images = len(images)
</code></pre>

<p><strong>Usage</strong></p>
<p>The <code>len()</code> <code>(__len__)</code> operator is overridden to return the number of <code>Image</code> objects in the collection.</p>
<h3 id="142">1.4.2 []</h3>
<p><strong>Synopsis</strong></p>
<pre><code class="python">image = images[n] 
</code></pre>

<p><strong>Usage</strong></p>
<p>The <code>[]</code> <code>(__getitem__)</code> operator is overridden to return the Image object at the specified index. </p>
<p><strong>Exceptions</strong></p>
<p>A <code>IndexError</code> is raised if the index is out of range.</p>
<h4 id="143-next">1.4.3 next()</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python">data, label = next(images) 
</code></pre>

<p><strong>Usage</strong></p>
<p>The <code>next()</code> operator is overridden and is used in conjunction with the split property. Once the collection has been split in training and test data, the <code>next()</code> operator will iterate through the training dataset one image, and corresponding label, at a time.</p>
<p>Once the training set has been fully iterated, the <code>next()</code> operator returns <code>None</code>, and will reset and start with the first element.  Additionally, the training set will be randomly reshuffled.</p>
<p>If the <code>augment</code> property is not False, for each image in the training set, one or more additional images are generated by rotating the image a random value between -90 and 90 degrees. For example, for a training set of a 1000 images, if the parameter to the property <code>augment</code> is True, the <code>next()</code> operator will iterate through 2000 images. If the parameter was a tuple and the number of augmentations per image was set to 2, the <code>next()</code> operator will iterate through 3000 images.</p>
<h4 id="144">1.4.4 +=</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python">images += image

images += images2
</code></pre>

<p><strong>Parameters</strong></p>
<p><strong>image:</strong> A single <code>Image</code> object</p>
<p><strong>images2:</strong> A single <code>Images</code> object (i.e., collection of <code>Image</code> objects).</p>
<p><strong>Usage</strong></p>
<p>The <code>[]</code> <code>(__iadd__)</code> operator is overridden to either add a single <code>Image</code> object or a <code>Images</code> object (i.e., collection) to an existing <code>Images</code> object. If the configuration setting 'nostore' is set for the parent <code>Images</code> object, the updated Images object is not stored to the corresponding HDF5 file, in which case one must explicity issue the <code>store()</code> method; otherwise ('nostore' is not set), the updated <code>Images</code> object is stored to the corresponding HDF5 file.
 
<strong>Exceptions</strong></p>
<p>A <code>TypeError</code> is raised if the type of the parameter is not the expected type.  </p>
<h3 id="15-images-public-methods">1.5 Images Public Methods</h3>
<h4 id="151-load">1.5.1 load()</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python">images.load(name, dir=None) 
</code></pre>

<p><strong>Parameters</strong></p>
<p><strong>name:</strong> The name of the collection. </p>
<p><strong>Usage</strong></p>
<p>This method will load into memory a preprocessed machine learning ready data from an HDF5 file specified by the collection name. The method will load the HDF5 by the filename <code>&lt;collection&gt;.h5</code>. If <code>dir</code> is None, then it will look for the file where the current value for <code>dir</code> is defined (either locally or reset by the <code>dir</code> property). Otherwise, it will look for the file under the directory specified by the <code>dir</code> parameter.</p>
<p>Once loaded, the <code>Images</code> object will have the same characteristics as when the <code>Images</code> object was created.</p>
<p><strong>Exceptions</strong></p>
<p>A <code>TypeError</code> is raised if the type of the parameter is not the expected type.<br />
A <code>ValueError</code> is raised if the name parameter is None.</p>
<h4 id="152-store">1.5.2 store()</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python">images.store() 
</code></pre>

<p><strong>Usage</strong></p>
<p>This method will store the machine learning ready data (and corresponding metadata) in a HDF5 file. 
 </p>
<h2 id="2-image">2 Image</h2>
<h3 id="21-image-overview">2.1 Image Overview</h3>
<p>The Image CV preprocessor contains the following primary classes, and their relationships:</p>
<ul>
<li>Image - This is the base class for the representation of a Computer Vision (CV) preprocessed image. The constructor optionally takes as parameters an image (path), and corresponding label, and flags for CV preprocessing of the image.</li>
</ul>
<pre><code class="python">image = Image(&lt;image_path&gt;, &lt;label&gt;, flags …)
</code></pre>

<p>The image path maybe a local path or an URL to a remote location, or raw pixel data as a numpy array. For remote location, a HTTP request is made to obtain the image data.</p>
<h3 id="22-image-initializer-constructor">2.2 Image Initializer (Constructor)</h3>
<p><strong>Synopsis</strong></p>
<pre><code class="python">Image(image=None, label= 0, dir=’./’, ehandler=None,  config=None)
</code></pre>

<p><strong>Parameters</strong></p>
<p><strong>image:</strong> If not None, a string of either:<br />
1.  local path to an image file<br />
2.  remote location of an image file (i.e., http[s]://….)<br />
3.  raw pixel data as a numpy array</p>
<p><strong>label:</strong> An integer value which is the label corresponding to the image.</p>
<p><strong>dir:</strong> The directory where to store the machine learning ready data.</p>
<p><strong>ehandler:</strong> If not None, the processing of the images into machine learning ready data will be asynchronous, and the value of the parameter is the function (or method) that is the event handler when processing is complete. The event handler takes the form:</p>
<pre><code class="python">def myHandler(image, dir): 
    # Where image is the Image object that was preprocessed.
</code></pre>

<p><strong>config:</strong> If not None, a list of one or more configuration settings as strings:<br />
            grayscale               | gray<br />
            flatten                 | flat<br />
            resize=(height,width)   | resize=height,width<br />
            thumb=(height,width)    | thumb=height,width<br />
        float=float16       | float32 | float64
            nostore
        raw</p>
<p><strong>Usage</strong></p>
<p>When specified with no parameters, an empty <code>Image</code> object is created. The <code>Image</code> object may then be used to subsequent load previously stored preprocessed machine learning ready data (see <code>load()</code>).</p>
<p>Otherwise, both <code>image</code> and <code>label</code> parameters must be specified.  The <code>label</code> parameter corresponds to the label of the image. The image specified by the <code>image</code> parameter will be preprocessed according to the optional parameters and configuration settings. By default, the image will be preprocessed as follows:</p>
<ol>
<li>Decompressed into raw pixel data.</li>
<li>Converted to RGB, if not already.</li>
<li>The pixel values are normalized (i.e., pixel integer values 0..255 converted to floating point values between 0 and 1).</li>
<li>Upon completion, the preprocessed machine learning data for the image is stored as a single HDF5 file in the current working directory. The root name of the file will be the root name of the image.</li>
<li>If the config setting 'raw' is specified, the raw pixel data for the image is additionally stored in the HDF5 file.</li>
<li>Attributes of the raw and preprocessed image are stored in the HDF5 file.</li>
</ol>
<p>If the path to an image file is remote (i.e., starts with http), an HTTP request will be made to fetch the contents of the file from the remote location.</p>
<p>If the parameter <code>dir</code> is specified, then the generated HDF5 file is stored in the specified directory. If the directory does not exist, it is created.</p>
<p>If the <code>ehandler</code> parameter is not None, then the above will occur asynchronously, and when completed, the corresponding event handler will be called with the <code>Image</code> object passed as a parameter. The <code>ehandler</code> parameter may also be specified as a tuple, where the first item in the tuple is the event handler and the remaining items are arguments to pass to the event handler.</p>
<p>If the configuration setting <code>grayscale</code> (may be shortened to gray) is specified, then the image is converted to a single channel grayscale image, if not already.</p>
<p>If the configuration setting <code>resize</code> is specified, then the image is resized to the specified height and width.</p>
<p>If the configuration setting <code>flatten</code> (may be shortened to flat) is specified, the image is flattened into a single 1D vector (i.e., for input to a ANN).</p>
<p>If the configuration setting <code>thumb</code> is specified, then a thumbnail of the raw pixel data is generated to the specified height and width and stored in the HDF5 file. </p>
<p>If the configuration setting <code>nostore</code> is specified, then the image data and corresponding metadata are not stored in the HDF5 file.</p>
<p>If the configuration setting <code>raw</code> is specirfied, then the raw pixel image data is stored in the HDF5 file.</p>
<p>By default, the data type of the preprocessed machine learning ready data is np.float32 (4 bytes per pixel). The data type can be change with the <code>config</code> parameter setting <code>float</code>, which can be set to either float16 (2 bytes per pixel), float32 (4 bytes per pixel) or float64 (8 bytes per pixel).</p>
<p><strong>Exceptions</strong></p>
<p>A <code>TypeError</code> is raised if the type of the parameter is not the expected type.<br />
A <code>AttributeError</code> is raised if an invalid configuration setting is specified.<br />
A <code>FileNotFoundError</code> is raised if the image file does not exist.<br />
A <code>IOError</code> is raised if an error occurs reading in the image file.</p>
<h3 id="23-image-properties">2.3 Image Properties</h3>
<h4 id="231-image">2.3.1 image</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
path = image.image

# Setter
image.image = path  
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter the property returns the path to the image file.  </p>
<p>When used as a setter the property specifies the path of the image file to preprocess into machine learning ready data (see initializer).</p>
<p><strong>Exceptions</strong></p>
<p>A <code>TypeError</code> is raised if the type of the parameter is not the expected type.<br />
A <code>FileNotFoundError</code> is raised if the image file does not exist.<br />
A <code>IOError</code> is raised if an error occurs reading in the image file.</p>
<h4 id="232-name">2.3.2 name</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
root = image.name
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter the property returns the root name of the image file (e.g., /mydir/myimage.jpg -&gt; myimage). If the input was raw pixel data, the name property will return ‘untitled’.</p>
<h4 id="233-type">2.3.3 type</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
suffix = image.type
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter the property returns the file suffix of the image file (e.g., jpg). If the input was raw pixel data, the property will return ‘raw’.</p>
<h4 id="234-size">2.3.4 size</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
size = image.size
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter the property returns the file size of the image file in bytes.</p>
<h4 id="235-raw">2.3.5 raw</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
pixels = image.raw
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter the property returns the raw pixel data of the uncompressed image.</p>
<h4 id="236-thumb">2.3.6 thumb</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
pixels = image.thumb
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter the property returns the pixel data for the thumbnail image.</p>
<h4 id="237-label">2.3.7 label</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
label = image.label

# Setter
image.label = label 
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter the property returns the (integer) label specified for the image. </p>
<p>When used as a setter the property sets the label of the image to the specified integer value.</p>
<p><strong>Exceptions</strong></p>
<p>A <code>TypeError</code> is raised if the type of the parameter is not the expected type.</p>
<h4 id="237-dir">2.3.7 dir</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
subfolder = image.dir

# Setter
image.dir = subfolder   
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter the property returns the directory path where the corresponding HDF5 file is stored.  </p>
<p>When used as a setter, it is only applicable when used in conjunction with the <code>load()</code> method, indicating where the path where the HDF5 file is found. Otherwise, it is ignored.</p>
<p><strong>Exceptions</strong></p>
<p>A <code>TypeError</code> is raised if the type of the parameter is not the expected type.<br />
A <code>FileNotFoundError</code> is raised if the directory does not exist.</p>
<h4 id="238-data">2.3.8 data</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
data = image.data
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter the property returns the preprocessed machine learning ready data.</p>
<h4 id="239-shape">2.3.9 shape</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
shape = image.shape
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter the property returns the shape of the preprocessed machine learning ready data (e.g., (50, 50, 3)).
 </p>
<h4 id="2310-time">2.3.10 time</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
secs = image.time
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter the property returns the amount of time (in seconds) it took to preprocess the image into machine learning ready data.</p>
<h4 id="2311-elapsed">2.3.11 elapsed</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python"># Getter
time_elapsed = image.elapsed
</code></pre>

<p><strong>Usage</strong></p>
<p>When used as a getter the property returns time (in hh:mm:ss format) it took to preprocess the image into machine learning ready data.</p>
<h3 id="24-image-overridden-operators">2.4 Image Overridden Operators</h3>
<h4 id="241-str">2.4.1 str()</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python">label = str(image)
</code></pre>

<p><strong>Usage</strong></p>
<p>The <code>str()</code> <code>(__str__)</code> operator is overridden to return the label of the image as a string.</p>
<h3 id="25-image-public-methods">2.5 Image Public Methods</h3>
<h4 id="251-load">2.5.1 load()</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python">image.load(name, dir=None) 
</code></pre>

<p><strong>Parameters</strong></p>
<p><strong>name:</strong> The filename of the stored HDF5 file. </p>
<p><strong>dir:</strong> The directory where the HDF5 file is located.</p>
<p><strong>Usage</strong></p>
<p>This method will load into memory a preprocessed machine learning ready data from an HDF5 file specified by the parameter name. The method will load the HDF5 by the filename <code>&lt;name&gt;.h5</code>. If dir is None, then it will look for the file where the current value for dir is defined (either locally or reset by the dir property). Otherwise, it will look for the file under the directory specified by the dir parameter.</p>
<p>Once loaded, the <code>Image</code> object will have the same characteristics as when the <code>Image</code> object was created.</p>
<p><strong>Exceptions</strong></p>
<p>A <code>TypeError</code> is raised if the type of the parameter is not the expected type.<br />
A <code>ValueError</code> is raised if the name parameter is None.</p>
<h4 id="252-rotate">2.5.2 rotate()</h4>
<p><strong>Synopsis</strong></p>
<pre><code class="python">image.rotate(degree) 
</code></pre>

<p><strong>Parameters</strong></p>
<p><strong>degree:</strong> The degree (angle) to rotate the image data.</p>
<p><strong>Usage</strong></p>
<p>This method generates a rotated copy of the raw image data. The parameter degree specifies the degree (angle) to rotate the image. The method uses the imutils module which will resize the image to prevent clipping prior to the rotation. Once rotated, the image is resized back to the target size.</p>
<p><strong>Exceptions</strong></p>
<p>A <code>TypeError</code> is raised if the type of the parameter is not the expected type.<br />
A <code>ValueError</code> is raised if the degree is not between 0 and 360.</p>
<hr />
<h2 id="appendix-i-updates">APPENDIX I: Updates</h2>
<p><strong>Pre-Gap (Epipog) v1.5</strong><br />
1.  Created first instance of module</p>
<p><strong>Gap v0.9 (alpha)</strong><br />
1.  Added splitting collection into training and test data<br />
2.  Added iterating (next) through the training set<br />
3.  Added support for minibatch</p>
<p><strong>Gap v0.9.1 (alpha)</strong><br />
1.  Added support for Images to take list of directories of images.<br />
2.  Added support for Image for image path is an URL (http request).<br />
3.  Added image rotation.<br />
4.  Rewrote Specification.<br />
5.  Added support for Images for image parameters to be folders of images.<br />
6.  Added support for GIF.<br />
7.  Added support for image augmentation in <code>next()</code>/minibatch.<br />
8.  Added support for raw pixel input to Image class.</p>
<p><strong>Gap v0.9.2 (alpha)</strong><br />
1.  Added support for mix image size/shape in Images object.<br />
2.  Added support += overriden operator.<br />
3.  Added support for specifying (min,max,n) for Image Augmentation.</p>
<p><strong>Gap v0.9.3 (alpha)</strong>
1.  Added converting to numpy arrays and one hot encoding of labels for Image split getter.
2.  Added raw setting to config parameter.
3.  Added float setting to config parameter.
4.  Added transformation property flatten.</p>
<p>Proprietary Information<br />
Copyright ©2018, Epipog, All Rights Reserved</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="../segmentation_spec/" class="btn btn-neutral" title="Segmentation"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/andrewferlitsch/Gap/" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../segmentation_spec/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>

</body>
</html>
